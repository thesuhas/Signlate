{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "856418670dd04c5e265467d5400639c8275fa4ff1ddf9eb7481f8b7f6558ac1a"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_path = \"//Users//divyashekar//Documents//archive//asl_alphabet_train//asl_alphabet_train\"\n",
    "testing_set_path = \"//Users//divyashekar//Documents//Signlate//archive//asl_alphabet_test//asl_alphabet_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 100\n",
    "num_classes = 29\n",
    "epochs = 100\n",
    "initializer = 'he_normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = image_dataset_from_directory('training_set_path', labels='inferred', label_mode='int', image_size=[100, 100], interpolation='nearest', batch_size=64, shuffle=False)\n",
    "validation_dataset = image_dataset_from_directory('testing_set_path', labels='inferred', label_mode='int', image_size=[100, 100], interpolation='nearest', batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def label(folder_name):\n",
    "    num = folder_name\n",
    "    if 'space' in num:\n",
    "        return 0\n",
    "    elif 'A' in num:\n",
    "        return 1 \n",
    "    elif 'B' in num:\n",
    "        return 2\n",
    "    elif 'C' in num:\n",
    "        return 3\n",
    "    elif 'D' in num:\n",
    "        return 4\n",
    "    elif 'E' in num:\n",
    "        return 5\n",
    "    elif 'F' in num:\n",
    "        return 6\n",
    "    elif 'G' in num:\n",
    "        return 7\n",
    "    elif 'H' in num:\n",
    "        return 8\n",
    "    elif 'I' in num:\n",
    "        return 9\n",
    "    elif 'J' in num:\n",
    "        return 10\n",
    "    elif 'K' in num:\n",
    "        return 11\n",
    "    elif 'L' in num:\n",
    "        return 12\n",
    "    elif 'M' in num:\n",
    "        return 13\n",
    "    elif 'N' in num:\n",
    "        return 14\n",
    "    elif 'O' in num:\n",
    "        return 15\n",
    "    elif 'P' in num:\n",
    "        return 16\n",
    "    elif 'Q' in num:\n",
    "        return 17\n",
    "    elif 'R' in num:\n",
    "        return 18\n",
    "    elif 'S' in num:\n",
    "        return 19\n",
    "    elif 'T' in num:\n",
    "        return 20\n",
    "    elif 'U' in num:\n",
    "        return 21\n",
    "    elif 'V' in num:\n",
    "        return 22\n",
    "    elif 'W' in num:\n",
    "        return 23\n",
    "    elif 'X' in num:\n",
    "        return 24\n",
    "    elif 'Y' in num:\n",
    "        return 25\n",
    "    elif 'Z' in num:\n",
    "        return 26\n",
    "    elif 'del' in num:\n",
    "        return 27\n",
    "    elif 'nothing' in num:\n",
    "        return 28\"\"\""
   ]
  },
  {
   "source": [
    "CREATING DATASET"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def create_dataset(path):\n",
    "    data = []\n",
    "    for folder in os.scandir(path):\n",
    "        if(os.path.isdir(folder.path)):\n",
    "            for image in os.scandir(os.path.join(path, folder)):\n",
    "                letter_label = label(folder.name)\n",
    "                if (letter_label == None):\n",
    "                    print(folder.name)\n",
    "                    break\n",
    "                img = cv2.imread(os.path.join(path, folder, image))\n",
    "\n",
    "                # Resize\n",
    "                new = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "                data.append([new, letter_label])\n",
    "    return data\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = create_dataset(training_set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "87000"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "X = np.array([d[0] for d in training_dataset])\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(87000, 100, 100, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "X = np.divide(X, 255)\n",
    "len(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "87000"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "y = np.array([d[1] for d in data])\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state = 1, stratify=y_train)\"\"\""
   ]
  },
  {
   "source": [
    "CNN MODEL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.InputLayer(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu', kernel_initializer=initializer),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.BatchNormalization(),\n",
    "    # Dropout layer for regularisation\n",
    "    layers.Dropout(rate=0.5),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu', kernel_initializer=initializer),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.BatchNormalization(),\n",
    "    # Dropout layer for regularisation\n",
    "    layers.Dropout(rate=0.5),\n",
    "    layers.Conv2D(64, 5, padding='same', activation='relu', kernel_initializer=initializer),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.BatchNormalization(),\n",
    "    # Dropout layer for regularisation\n",
    "    layers.Dropout(rate=0.5),\n",
    "    # Flattening output to connect to Densely Connected Layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu', kernel_initializer=initializer),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(num_classes, activation='softmax', kernel_initializer=initializer)\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  }
 ]
}